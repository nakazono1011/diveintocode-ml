{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "hide_input": false,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "Sprint12_CNN1d_fullscratch_guide.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GExWZJ2vxzmk",
        "colab_type": "text"
      },
      "source": [
        "# 一次元畳み込みニューラルネットワークの実装"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZ79rL2Gxzml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5Pz1zkqxzmp",
        "colab_type": "text"
      },
      "source": [
        "## まず適当なテストデータを作る\n",
        "1dCNNは多くの場合で時系列解析に用いられます。そのため、テストデータは簡単な異常検知モデルにしてみましょう。\n",
        "\n",
        "※本来、時系列の異常検知システムは逐次的に見ることが多いので、本当はこんな風にバッチごとに見るようなことは少ないです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NFouaeHxzmp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "outputId": "83059ce8-92e7-430a-a268-a69aaabac955"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "X_train = X_train.reshape(-1, 1, 784)\n",
        "X_test = X_test.reshape(-1, 1, 784)\n",
        "\n",
        "print(X_train.shape) # (60000, 28, 28)\n",
        "print(X_test.shape) # (10000, 28, 28)\n",
        "print(X_train[0].dtype) # uint8\n",
        "print(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 1, 784)\n",
            "(10000, 1, 784)\n",
            "uint8\n",
            "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   3  18  18  18 126 136 175  26 166 255\n",
            "  247 127   0   0   0   0   0   0   0   0   0   0   0   0  30  36  94 154\n",
            "  170 253 253 253 253 253 225 172 253 242 195  64   0   0   0   0   0   0\n",
            "    0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251  93  82\n",
            "   82  56  39   0   0   0   0   0   0   0   0   0   0   0   0  18 219 253\n",
            "  253 253 253 253 198 182 247 241   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0  14   1 154 253  90   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0  11 190 253  70   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  35 241\n",
            "  225 160 108   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0  81 240 253 253 119  25   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  45 186 253 253 150  27   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252 253 187\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0 249 253 249  64   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
            "  253 207   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0  39 148 229 253 253 253 250 182   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253\n",
            "  253 201  78   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0  23  66 213 253 253 253 253 198  81   2   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0  18 171 219 253 253 253 253 195\n",
            "   80   9   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   55 172 226 253 253 253 253 244 133  11   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0 136 253 253 253 212 135 132  16\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "    0   0   0   0   0   0   0   0   0   0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dng4BKv4ySGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(-1, 1, 784)\n",
        "X_test = X_test.reshape(-1, 1, 784)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPTnvhaBybfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train[:2400]\n",
        "y_train = y_train[:2400]\n",
        "X_test = X_test[:600]\n",
        "y_test = y_test[:600]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGkH9ZcyfeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "3bae21f2-2e48-4343-b1d4-a6c2fde96c6d"
      },
      "source": [
        "index = 0\n",
        "image = X_train[index].reshape(28,28)\n",
        "plt.imshow(image, 'gray')\n",
        "plt.title('label : {}'.format(y_train[index]))\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8NGNe-HymKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "90fc385d-5f42-4b44-dfb8-79706b0ca75a"
      },
      "source": [
        "X_train = X_train.astype(np.float)\n",
        "X_test = X_test.astype(np.float)\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.max()) # 1.0\n",
        "print(X_train.min()) # 0.0\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
        "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
        "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
        "\n",
        "print(y_train.shape) # (60000,)\n",
        "print(y_train_one_hot.shape) # (60000, 10)\n",
        "print(y_train_one_hot.dtype) # float64\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
        "\n",
        "print(X_train.shape, y_train.shape) # (48000, 784)\n",
        "print(X_val.shape, y_val.shape) # (12000, 784)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "0.0\n",
            "(2400,)\n",
            "(2400, 10)\n",
            "float64\n",
            "(1920, 1, 784) (1920, 10)\n",
            "(480, 1, 784) (480, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0UCVyNQxzmx",
        "colab_type": "text"
      },
      "source": [
        "### 【問題2】1次元畳み込み後の出力サイズの計算\n",
        "\n",
        "$$\n",
        "N_{out} = \\frac{N_{in}+2P-F}{S}+1\n",
        "$$\n",
        "\n",
        "$N_{out}$ : 出力のサイズ（特徴量の数）\n",
        "\n",
        "\n",
        "$N_{in}$ : 入力のサイズ（特徴量の数）\n",
        "\n",
        "\n",
        "$P$ : ある方向へのパディングの数\n",
        "\n",
        "\n",
        "$F$ : フィルタのサイズ\n",
        "\n",
        "\n",
        "$S$ : ストライドのサイズ\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqUT7pODxzmy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_out_shape(N_in, P, F, S):\n",
        "    N_out = ((N_in + 2 * P - F) / S) + 1\n",
        "    return int(N_out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_1YOAVpxzm0",
        "colab_type": "code",
        "colab": {},
        "outputId": "36a49d1b-8025-4ce2-83d9-64cec069638b"
      },
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])\n",
        "padding=0\n",
        "stride = 1\n",
        "\n",
        "calc_out_shape(4, padding, len(w), stride)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaypj58jxzm3",
        "colab_type": "text"
      },
      "source": [
        "### 【問題１】チャンネル数の1に限定した一次元畳み込み層のクラスの作成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwGzV-WUxzm3",
        "colab_type": "text"
      },
      "source": [
        "一次元畳み込み層のクラスを作成しましょう。DNNの時と同じような設計になるように、見比べながらやるといいです。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkeE3tqexznJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Scratch1dCNNClassifier:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self):       \n",
        "        self.W = np.array([3,5,7]) \n",
        "        self.B = np.array([1])\n",
        "        self.padding = 0\n",
        "        self.strides = 1        \n",
        "        self.filters = len(self.W)\n",
        "        self.a = np.array([])\n",
        "        self.dW = np.array([])\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes_bf)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_af)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.N_in = len(self.X)\n",
        "        self.N_out = int((self.N_in + 2*self.padding - self.filters) / self.strides + 1) # 出力サイズの計算\n",
        "        \n",
        "        self.a = np.append(self.a, [np.dot(self.X[i : i+self.filters], self.W) + self.B for i in range(self.N_out)])\n",
        "\n",
        "        return self.a\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            後ろから流れてきた勾配\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        self.dB = np.sum(dA, axis=0)        \n",
        "        self.dW = np.append(self.dW, [np.dot(self.X[i : i+self.N_out].T, dA) for i in range(self.filters)])\n",
        "\n",
        "\n",
        "        self.dX = np.zeros(len(self.X))            \n",
        "        for j in range(len(self.X)):\n",
        "            for s in range(len(self.W)):\n",
        "                if j - s < 0 or j - s > 1:\n",
        "                    self.dX[j] = self.dX[j]\n",
        "                else:\n",
        "                    self.dX[j] = self.dX[j] + dA[j - s] * self.W[s]\n",
        "\n",
        "        return self.dX"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcdXv0I6xznM",
        "colab_type": "text"
      },
      "source": [
        "### 【問題3】小さな配列での1次元畳み込み層の実験"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1UewVOsxznM",
        "colab_type": "text"
      },
      "source": [
        "フォワードプロパゲーションでは入力とパラメータが以下のようになっているとき"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi51PxmdxznN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = np.array([1,2,3,4])\n",
        "w = np.array([3, 5, 7])\n",
        "b = np.array([1])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktl-db1pxznP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9c29e840-b2fc-456e-977a-f9503f9a8fb8"
      },
      "source": [
        "model = Scratch1dCNNClassifier()\n",
        "model.forward(x)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35., 50.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WryNI15xznS",
        "colab_type": "text"
      },
      "source": [
        "出力はこうなっているはずです\n",
        "```python\n",
        "a = np.array([35, 50])\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hec5IXwxznT",
        "colab_type": "text"
      },
      "source": [
        "バックプロパゲーションで誤差が以下のようなとき"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C02bpml9xznT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28cb8ed0-66ea-4760-bf93-ebd14c5364ff"
      },
      "source": [
        "delta_a = np.array([10, 20])\n",
        "model.backward(delta_a)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 30., 110., 170., 140.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3CINwmAxznX",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "delta_b = np.array([30])\n",
        "delta_w = np.array([50, 80, 110])\n",
        "delta_x = np.array([30, 110, 170, 140])\n",
        "```\n",
        "と、このようになります。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXcEfNQixznX",
        "colab_type": "text"
      },
      "source": [
        "### 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYW8zfqKxznX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv1d:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self):       \n",
        "        self.W = np.ones((3, 2, 3)) \n",
        "        self.B = np.array([1, 2, 3])\n",
        "        self.padding = 0\n",
        "        self.strides = 1        \n",
        "        self.filters = self.W.shape[2]        \n",
        "        #self.a = np.array([])\n",
        "        #self.dW = np.array([])\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes_bf)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_af)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        self.N_in = self.X.shape[1]\n",
        "        self.N_out = int((self.N_in + 2*self.padding - self.filters) / self.strides + 1) # 出力サイズの計算\n",
        "\n",
        "        self.a = np.zeros((self.W.shape[0], self.N_out)) #出力チャネル数、出力サイズ\n",
        "        for i in range(self.W.shape[0]): #出力チャネル\n",
        "            for j in range(self.X.shape[0]): #入力チャネル\n",
        "                for s in range(self.N_out): #出力サイズ\n",
        "                    self.a[i, j] = self.a[i, j] + np.dot(self.X[j, s: s+self.filters], self.W[i, j])\n",
        "                    \n",
        "        #バイアス\n",
        "        self.a = self.a + self.B.reshape(-1, 1)\n",
        "\n",
        "        return self.a\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            後ろから流れてきた勾配\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        self.dB = np.sum(dA, axis=1)\n",
        "        \n",
        "        self.dW = np.zeros((self.W.shape[0], self.X.shape[0], self.filters)) #出力チャネル数、出力サイズ、フィルタサイズ\n",
        "        for i in range(self.W.shape[0]): #出力チャネル\n",
        "            for j in range(self.X.shape[0]): #入力チャネル\n",
        "                for s in range(self.filters): #フィルタサイズ\n",
        "                        self.dW[i, j, s] = np.dot(self.X[j][s : s+self.N_out].T, dA[s])\n",
        "\n",
        "        self.dX = np.zeros(self.X.shape)\n",
        "        for i in range(self.W.shape[0]): #出力チャネル\n",
        "            for j in range(self.X.shape[0]): #入力チャネル\n",
        "                for s in range(self.filters): #フィルタサイズ\n",
        "                    for n in range(self.N_out): #出力サイズ\n",
        "                        self.dX[j, s + n] = self.dX[j, s + n] + dA[i, n] * self.W[i, j, s]\n",
        "\n",
        "        return self.dX"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZetK2K5mxznZ",
        "colab_type": "text"
      },
      "source": [
        "問題３と同じく出力を確認しましょう。\n",
        "\n",
        "フォワードプロパゲーションでは入力とパラメータが以下のようになっているとき"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RFxg2c1xzna",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Conv1d()\n",
        "x = np.array([[1, 2, 3, 4], [2, 3, 4, 5]]) # shape(2, 4)で、（入力チャンネル数、特徴量数）である。\n",
        "w = np.ones((3, 2, 3)) # 例の簡略化のため全て1とする。(出力チャンネル数、入力チャンネル数、フィルタサイズ)である。\n",
        "b = np.array([1, 2, 3]) # （出力チャンネル数）"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5mE5-qnxznb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "129584ad-0d1f-435d-dfdd-6802cd13c8d6"
      },
      "source": [
        "model.forward(x)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[16., 22.],\n",
              "       [17., 23.],\n",
              "       [18., 24.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT7C4kTexznd",
        "colab_type": "text"
      },
      "source": [
        "```python\n",
        "a = np.array([[16, 22], [17, 23], [18, 24]])\n",
        "```\n",
        "\n",
        "となっていれば正解です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODNfUEK-xzne",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e173b76-3435-4316-e994-5aab248cbdd0"
      },
      "source": [
        "delta_a = np.array([[10, 20], [10, 20], [10, 20]])\n",
        "model.backward(delta_a)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[30., 90., 90., 60.],\n",
              "       [30., 90., 90., 60.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6kxis-3xzni",
        "colab_type": "text"
      },
      "source": [
        "### 【問題8】学習と推定\n",
        "\n",
        "これまでと同じように、活性化関数やOptimizerのクラス（関数）を組み合わせて学習・推定させましょう。\n",
        "チャンネル数が１よりも大きいときはうまく実行できません。なので、**平滑化**を行えるクラス（関数）を作りましょう。\n",
        "発展的にGlobal Average Pollingを実装しても問題ありません。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNa6B7Mmxznj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Flatten():\n",
        "    def __init__(self):\n",
        "        self.X_shape = None\n",
        "    \n",
        "    def forward(self, X):\n",
        "        # 1次元化\n",
        "        X_1d = X.reshape(X.shape[0], -1)\n",
        "        \n",
        "        # shapeの記録\n",
        "        self.X_shape = X.shape\n",
        "        \n",
        "        return X_1d    \n",
        "\n",
        "    def backward(self, X):\n",
        "        # shapeの返戻\n",
        "        X = X.reshape(self.X_shape)\n",
        "        \n",
        "        return X"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqcp06y2xznl",
        "colab_type": "text"
      },
      "source": [
        "DNNの時と同じようにモデル全体を作っていきましょう。\n",
        "まずは上に用意したデータなどで試して見てください。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pUogsnGxznl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Scratch1dCNNClassifier:\n",
        "    \"\"\"\n",
        "    ディープニューラルネットワーク分類器\n",
        "\n",
        "    Parameters\n",
        "    --------------\n",
        "    activaiton : {'sigmoid', 'tanh', 'relu'} \n",
        "        活性化関数の種類\n",
        "    n_nodes : list\n",
        "        ノードの構成 例 [400, 200, 100]\n",
        "    n_output : int\n",
        "        出力層の数\n",
        "    alpha : float\n",
        "        学習率\n",
        "    optimizer :  {'sgd', 'adagrad'}\n",
        "        最適化手法の種類\n",
        "    filter_num : int\n",
        "        フィルタ数\n",
        "    filter_size : int\n",
        "        フィルタサイズ\n",
        "        \n",
        "    Attributes\n",
        "    -------------\n",
        "    FC[n_layers] :  dict\n",
        "        結合層を管理する辞書\n",
        "    activation : dict\n",
        "        活性化関数を管理する辞書\n",
        "    self.epochs : int\n",
        "        エポック数(初期値：10)\n",
        "    self.batch_size : int\n",
        "        バッチサイズ(初期値：20)\n",
        "    self.n_features : int\n",
        "        特徴量の数\n",
        "    self.val_is_true : boolean\n",
        "        検証用データの有無    \n",
        "    self.loss : 空のndarray\n",
        "        訓練データに対する損失の記録\n",
        "    self.loss_val : 空のndarray\n",
        "        検証データに対する損失の記録\n",
        "        \n",
        "    \"\"\"    \n",
        "    def __init__(self, activation, n_nodes, n_output, lr, optimizer, filter_num, filter_size):\n",
        "        self.select_activation = activation\n",
        "        self.n_nodes = n_nodes\n",
        "        self.n_output = n_output\n",
        "        self.lr = lr\n",
        "        self.select_optimizer = optimizer\n",
        "        \n",
        "        # Sprint11 追加*******************************\n",
        "        self.filter_num  = filter_num                         # フィルタ数\n",
        "        self.filter_size   = filter_size    # フィルタサイズ\n",
        "        # Sprint11 追加*******************************\n",
        "            \n",
        "    def __initialize_n_layers(self):\n",
        "        \"\"\"\n",
        "        N層を初期化する。\n",
        "        sigmoid関数とtanh関数が活性化関数の場合：Xavierを初期値\n",
        "        ReLU関数が活性化関数の場合：Heを初期値\n",
        "        \"\"\"\n",
        "        self.activation = dict()\n",
        "        self.FC = dict()\n",
        "        # Sprint11 追加*********************************************************************\n",
        "        #n_nodes = self.out // (2**(1))\n",
        "        if self.select_activation == 'sigmoid':\n",
        "            self.FC[0] = FC(self.out, self.n_nodes[0], \n",
        "                            XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "            self.activation[0] = Sigmoid()\n",
        "        elif self.select_activation == 'tanh':\n",
        "            self.FC[0] = FC(self.out, self.n_nodes[0], \n",
        "                            XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "            self.activation[0] = Tanh()\n",
        "        elif self.select_activation == 'relu':\n",
        "            self.FC[0] = FC(self.out, self.n_nodes[0], \n",
        "                            HeInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "            self.activation[0] = ReLU()\n",
        "        # Sprint11 追加*********************************************************************\n",
        "\n",
        "        for n_layer in range(len(self.n_nodes)):            \n",
        "            if n_layer == len(self.n_nodes) -1:\n",
        "                if self.select_activation == 'sigmoid':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_output, \n",
        "                                              XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = Softmax()\n",
        "                elif self.select_activation == 'tanh':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_output,\n",
        "                                              XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = Softmax()\n",
        "                elif self.select_activation == 'relu':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_output,\n",
        "                                              HeInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = Softmax()\n",
        "            else:\n",
        "                if self.select_activation == 'sigmoid':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_nodes[n_layer+1], \n",
        "                                              XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = Sigmoid()\n",
        "                elif self.select_activation == 'tanh':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_nodes[n_layer+1],\n",
        "                                              XavierInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = Tanh()\n",
        "                elif self.select_activation == 'relu':\n",
        "                    self.FC[n_layer + 1] = FC(self.n_nodes[n_layer], self.n_nodes[n_layer+1],\n",
        "                                              HeInitializer(filter_num=None, input_channel=None, filter_size=None), self.optimizer)\n",
        "                    self.activation[n_layer + 1] = ReLU()\n",
        "    \n",
        "    def fit(self, X, y, epochs=10, batch_size=20):  \n",
        "        self.epochs = epochs                            # エポック数     \n",
        "        self.batch_size = batch_size               # バッチサイズ\n",
        "        self.loss = np.zeros(self.epochs)        # 学習曲線・目的関数の出力用(訓練データ)\n",
        "        self.loss_val = np.zeros(self.epochs) # 学習曲線・目的関数の出力用(検証データ)        \n",
        "        \n",
        "        if self.select_optimizer == 'sgd':\n",
        "            self.optimizer = SGD(self.lr)\n",
        "        elif self.select_optimizer == 'adagrad':\n",
        "            self.optimizer = AdaGrad(self.lr)            \n",
        "        \n",
        "        # Sprint11 追加*********************************************************************\n",
        "        # 畳み込み層クラス\n",
        "        self.input_channel = X.shape[1]\n",
        "        self.input_feature = X.shape[2]\n",
        "        \n",
        "        self.conv1d = Conv1d(self.select_activation, self.optimizer, self.filter_num, self.input_channel, self.filter_size)\n",
        "        if self.select_activation == 'sigmoid':\n",
        "            self.activation_conv = Sigmoid()\n",
        "        elif self.select_activation == 'tanh':\n",
        "            self.activation_conv = Tanh()\n",
        "        elif self.select_activation == 'relu':\n",
        "            self.activation_conv = ReLU()\n",
        " \n",
        "        #ミニバッチの取得\n",
        "        get_mini_batch = GetMiniBatch(X, y, self.batch_size)\n",
        "\n",
        "        # 平滑化クラス\n",
        "        self.flatten = Flatten()\n",
        "        self.out = self.filter_num * (self.input_feature - (self.filter_size - 1))\n",
        "        # Sprint11 追加*********************************************************************        \n",
        "        \n",
        "        self.__initialize_n_layers()\n",
        "        \n",
        "        for epoch in range(self.epochs):\n",
        "            #get_mini_batch = GetMiniBatch(X, y, batch_size=self.batch_size) # Sprint11 削除\n",
        "            print(\"epoch \", epoch + 1 , \" processing . . .\")\n",
        "            for mini_X_train,  mini_y_train in get_mini_batch:\n",
        "                self.X_ = mini_X_train\n",
        "                self.y_ = mini_y_train\n",
        "                \n",
        "                # フォワードプロバゲーション\n",
        "                # Sprint11 追加*********************************************************************\n",
        "                #畳み込み(1層目)\n",
        "                self.A = self.conv1d.forward(self.X_) \n",
        "                self.Z = self.activation_conv.forward(self.A)    \n",
        "                \n",
        "                #平滑化\n",
        "                self.F = self.flatten.forward(self.Z)\n",
        "                               \n",
        "                self.A = self.FC[0].forward(self.F)\n",
        "                self.Z = self.activation[0].forward(self.A)                         \n",
        "                \n",
        "                # Sprint11 追加*********************************************************************\n",
        "                \n",
        "                self.A = self.FC[1].forward(self.Z)            #1層目\n",
        "                self.Z = self.activation[1].forward(self.A) #1層目\n",
        "                for n_layer in range(2, len(self.n_nodes) + 1): #2層目以降\n",
        "                    self.A = self.FC[n_layer].forward(self.Z)\n",
        "                    self.Z = self.activation[n_layer].forward(self.A)\n",
        "                \n",
        "                # バックプロパゲーション\n",
        "                self.dA, self.loss[epoch] = self.activation[len(self.n_nodes)].backward(self.Z, self.y_) #最終層, 交差エントロピー誤差\n",
        "                self.dZ = self.FC[len(self.n_nodes)].backward(self.dA) #最終層           \n",
        "                for n_layer in reversed(range(0, len(self.n_nodes))): #最終層 - 1\n",
        "                    self.dA = self.activation[n_layer].backward(self.dZ)\n",
        "                    self.dZ = self.FC[n_layer].backward(self.dA)\n",
        "\n",
        "                # Sprint11 追加********************************\n",
        "                # shapeの戻入\n",
        "                self.dF = self.flatten.backward(self.dZ)\n",
        "                \n",
        "                # 畳み込み層\n",
        "                self.dA = self.activation_conv.backward(self.dF)\n",
        "                self.dZ = self.conv1d.backward(self.dA)\n",
        "                # Sprint11 追加********************************\n",
        "                \n",
        "    def predict(self,X):\n",
        "        \n",
        "        # Sprint11 追加********************************\n",
        "        #畳み込み(1層目)\n",
        "        self.A = self.conv1d.forward(X) \n",
        "        self.Z = self.activation_conv.forward(self.A)    \n",
        "\n",
        "        #平滑化\n",
        "        self.F = self.flatten.forward(self.Z)\n",
        "\n",
        "        self.A = self.FC[0].forward(self.F)            #1層目\n",
        "        self.Z = self.activation[0].forward(self.A) #1層目\n",
        "        # Sprint11 追加********************************\n",
        "        \n",
        "        # フォワードプロバゲーション\n",
        "        self.A = self.FC[1].forward(self.Z)                     #1層目\n",
        "        self.Z = self.activation[1].forward(self.A) #1層目\n",
        "        for n_layer in range(2, len(self.n_nodes) + 1): #2層目以降\n",
        "            self.A = self.FC[n_layer].forward(self.Z)\n",
        "            self.Z = self.activation[n_layer].forward(self.A)\n",
        "        \n",
        "        return np.argmax(self.Z, axis=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23nF__Pxznn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Conv1d:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, activation, optimizer, filter_num, input_channel, filter_size):\n",
        "        self.activation = activation\n",
        "        self.optimizer = optimizer\n",
        "        self.filter_num = filter_num\n",
        "        self.input_channel = input_channel\n",
        "        self.filter_size = filter_size\n",
        "        self.pad = 0\n",
        "        self.stride = 1\n",
        "        \n",
        "        if self.activation == 'sigmoid':\n",
        "            initializer = XavierInitializer(self.filter_num, self.input_channel, self.filter_size)\n",
        "            self.W = initializer.W(_, _)\n",
        "            self.B = initializer.B(_)            \n",
        "        elif self.activation == 'tanh':\n",
        "            initializer = XavierInitializer(self.filter_num, self.input_channel, self.filter_size)\n",
        "            self.W = initializer.W(_, _)\n",
        "            self.B = initializer.B(_)          \n",
        "        elif self.activation == 'relu':\n",
        "            initializer = HeInitializer(self.filter_num, self.input_channel, self.filter_size)\n",
        "            self.W = initializer.W(_, _)\n",
        "            self.B = initializer.B(_)\n",
        "\n",
        "        self.X = None\n",
        "        self.N_in = None\n",
        "        self.N_out = None\n",
        "        self.a = None\n",
        "        self.dB = None\n",
        "        self.dW = None\n",
        "        self.dX = None\n",
        "        \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes_bf)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes_af)\n",
        "            出力\n",
        "        \"\"\"\n",
        "        self.X = X\n",
        "        \n",
        "        #shapeの取得\n",
        "        batch_size, input_channel, self.N_in = self.X.shape #(バッチサイズ, 入力チャンネル, 特徴量)\n",
        "        FN, C, FS = self.W.shape #(出力チャンネル,  入力チャンネル, フィルタサイズ)\n",
        "        \n",
        "        self.N_out = int((self.N_in + 2*self.pad - self.filter_size) / self.stride + 1) # 出力サイズの計算\n",
        "\n",
        "        self.a = np.zeros((batch_size, FN, self.N_out)) #バッチサイズ、出力チャネル数、出力サイズ\n",
        "        for b in range(batch_size): # バッチサイズ\n",
        "            for i in range(FN): #出力チャネル\n",
        "                for j in range(C): #入力チャネル\n",
        "                    for s in range(self.N_out): #出力サイズ\n",
        "                        self.a[b, i, s] = self.a[b, i, s] + np.sum(self.X[b, j, s: s+self.filter_size] * self.W[i, j, :])\n",
        "                        \n",
        "        #バイアス\n",
        "        self.a = self.a + self.B.reshape(1, -1, 1)\n",
        "\n",
        "        return self.a\n",
        "       \n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            後ろから流れてきた勾配\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        batch, C, W = self.X.shape # (バッチサイズ、入力チャンネル数、特徴量数)\n",
        "        FN, C, FS = self.W.shape # (出力チャンネル数、入力チャンネル数、フィルタサイズ)\n",
        "        \n",
        "        #空の配列\n",
        "        self.dW = np.zeros(self.W.shape) #Wの勾配\n",
        "        self.dX = np.zeros(self.X.shape) #Xの勾配\n",
        "\n",
        "        self.dB = np.sum(dA, axis=2)\n",
        "        \n",
        "        for b in range(batch): # バッチサイズ\n",
        "            for i in range(FN): #出力チャネル\n",
        "                for j in range(C): #入力チャネル\n",
        "                    for s in range(FS): #フィルタサイズ\n",
        "                        for x in range(self.N_out): #特徴量\n",
        "                            self.dW[i, j, s] = self.dW[i, j, s] + dA[b, i, x] * self.X[b, j, s + x]\n",
        "                            self.dX[b, j, s + x] = self.dX[b, j, s + x] + dA[b, i, x] * self.W[i, j, s]\n",
        "\n",
        "        # 更新\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return self.dX"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzCztBTG0HFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FC:\n",
        "    \"\"\"\n",
        "    ノード数n_nodes1からn_nodes2への全結合層\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_nodes1 : int\n",
        "      前の層のノード数\n",
        "    n_nodes2 : int\n",
        "      後の層のノード数\n",
        "    initializer : 初期化方法のインスタンス\n",
        "    optimizer : 最適化手法のインスタンス\n",
        "    \"\"\"\n",
        "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
        "        self.n_nodes1 = n_nodes1\n",
        "        self.n_nodes2 = n_nodes2\n",
        "        self.optimizer = optimizer\n",
        "        \n",
        "        # 初期化\n",
        "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
        "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
        "        self.B = initializer.B(n_nodes2)\n",
        "    \n",
        "    def forward(self, X):\n",
        "        \"\"\"\n",
        "        フォワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            入力\n",
        "        Returns\n",
        "        ----------\n",
        "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            出力\n",
        "        \"\"\"        \n",
        "        self.X = X\n",
        "        \n",
        "        return np.dot(self.X, self.W) + self.B\n",
        "    \n",
        "    def backward(self, dA):\n",
        "        \"\"\"\n",
        "        バックワード\n",
        "        Parameters\n",
        "        ----------\n",
        "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
        "            後ろから流れてきた勾配\n",
        "        Returns\n",
        "        ----------\n",
        "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
        "            前に流す勾配\n",
        "        \"\"\"\n",
        "        self.dB = dA\n",
        "        self.dW = np.dot(self.X.T, dA)\n",
        "        dZ = np.dot(dA, self.W.T)\n",
        "\n",
        "        # 更新\n",
        "        self = self.optimizer.update(self)\n",
        "        \n",
        "        return dZ"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEfv0i2o0JuI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class XavierInitializer:\n",
        "    \"\"\"\n",
        "    Xavierのクラス\n",
        "    \"\"\"\n",
        "    # Sprint11 追加*******************************\n",
        "    def __init__(self, filter_num=None, input_channel=None, filter_size=None):        \n",
        "        self.filter_num = filter_num\n",
        "        self.input_channel = input_channel\n",
        "        self.filter_size = filter_size\n",
        "    # Sprint11 追加*******************************  \n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          前の層のノード数\n",
        "        n_nodes2 : int\n",
        "          後の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
        "            重み\n",
        "        \"\"\"\n",
        "        # Sprint11 追加*******************************        \n",
        "        if self.filter_num and self.input_channel and self.filter_size is not None: # 畳み込み層\n",
        "            W = np.random.randn(self.filter_num, self.input_channel, self.filter_size)\n",
        "        else: # 全結合層\n",
        "        # Sprint11 追加*******************************\n",
        "            W = np.random.randn(n_nodes1, n_nodes2) / np.sqrt(n_nodes1)       \n",
        "        \n",
        "        return W\n",
        "        \n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          後の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : 次の形のndarray, shape (n_nodes2, )\n",
        "            バイアス\n",
        "        \"\"\"\n",
        "        # Sprint11 追加*******************************        \n",
        "        if self.filter_num and self.input_channel and self.filter_size is not None: # 畳み込み層\n",
        "            B = np.random.randn(self.filter_num)\n",
        "        else: # 全結合層\n",
        "        # Sprint11 追加*******************************\n",
        "            B = np.zeros(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROFOsoNW0LtY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class HeInitializer:\n",
        "    \"\"\"\n",
        "    Heのクラス\n",
        "    \"\"\"\n",
        "    # Sprint11 追加*******************************\n",
        "    def __init__(self, filter_num=None, input_channel=None, filter_size=None):        \n",
        "        self.filter_num = filter_num\n",
        "        self.input_channel = input_channel\n",
        "        self.filter_size = filter_size\n",
        "    # Sprint11 追加*******************************        \n",
        "        \n",
        "    def W(self, n_nodes1, n_nodes2):\n",
        "        \"\"\"\n",
        "        重みの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes1 : int\n",
        "          前の層のノード数\n",
        "        n_nodes2 : int\n",
        "          後の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        W : 次の形のndarray, shape (n_nodes1, n_nodes2)\n",
        "            重み\n",
        "        \"\"\"\n",
        "        # Sprint11 追加*******************************        \n",
        "        if self.filter_num and self.input_channel and self.filter_size is not None: # 畳み込み層\n",
        "            W = np.random.randn(self.filter_num, self.input_channel, self.filter_size) * np.sqrt(2 / self.filter_num) \n",
        "        else: # 全結合層\n",
        "        # Sprint11 追加*******************************\n",
        "            W = np.random.randn(n_nodes1, n_nodes2) * np.sqrt(2 / n_nodes1)\n",
        "    \n",
        "        return W\n",
        "        \n",
        "    def B(self, n_nodes2):\n",
        "        \"\"\"\n",
        "        バイアスの初期化\n",
        "        Parameters\n",
        "        ----------\n",
        "        n_nodes2 : int\n",
        "          後の層のノード数\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        B : 次の形のndarray, shape (n_nodes2, )\n",
        "            バイアス\n",
        "        \"\"\"\n",
        "        # Sprint11 追加*******************************        \n",
        "        if self.filter_num and self.input_channel and self.filter_size is not None: # 畳み込み層\n",
        "            B = np.random.randn(self.filter_num)\n",
        "        else: # 全結合層\n",
        "        # Sprint11 追加*******************************\n",
        "            B = np.random.randn(n_nodes2)\n",
        "        \n",
        "        return B"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMFM0R3X0OHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SGD:\n",
        "    \"\"\"\n",
        "    確率的勾配降下法\n",
        "    Parameters\n",
        "    ----------\n",
        "    lr : 学習率\n",
        "    \"\"\"\n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        \n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        ある層の重みやバイアスの更新\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : 更新前の層のインスタンス\n",
        "        \n",
        "        Returns\n",
        "        ----------\n",
        "        layer : 更新後の層のインスタンス\n",
        "        \"\"\"\n",
        "        layer.W = layer.W - self.lr * layer.dW\n",
        "        layer.B = layer.B - self.lr * layer.dB.mean(axis=0)\n",
        "        \n",
        "        return layer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRGWiMRw0P1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AdaGrad:\n",
        "    \"\"\"\n",
        "    AdaGradのクラス\n",
        "    Parameters\n",
        "    ----------\n",
        "    alpha : 学習率\n",
        "    \n",
        "    Attributes\n",
        "    -------------\n",
        "    lr : 学習率\n",
        "    HW : int(初期値), ndarray\n",
        "    HB :  int(初期値), ndarray\n",
        "    \"\"\"    \n",
        "    def __init__(self, lr):\n",
        "        self.lr = lr\n",
        "        self.HW= 0 # 初期値：0\n",
        "        self.HB = 0 # 初期値：0       \n",
        "\n",
        "    def update(self, layer):\n",
        "        \"\"\"\n",
        "        ある層の重みやバイアスの更新\n",
        "        Parameters\n",
        "        ----------\n",
        "        layer : インスタンス\n",
        "            更新前の層のインスタンス\n",
        "\n",
        "        Returns\n",
        "        ----------\n",
        "        layer : インスタンス\n",
        "            更新後の層のインスタンス\n",
        "        \"\"\"\n",
        "        #初期化\n",
        "        self.HW = np.zeros_like(layer.W)\n",
        "        self.HB = np.zeros_like(layer.B)\n",
        "        \n",
        "        #更新\n",
        "        self.HW = self.HW + (layer.dW**2) #/ layer.dB.shape[0]\n",
        "        self.HB = self.HB + (layer.dB**2).mean(axis=0)\n",
        "        layer.W = layer.W - self.lr * 1 / np.sqrt(self.HW + 1e-7) * layer.dW #/ layer.dB.shape[0]\n",
        "        layer.B = layer.B - self.lr * 1 / np.sqrt(self.HB + 1e-7) * layer.dB.mean(axis=0)\n",
        "        \n",
        "        return layer"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7JXmFNF0RZ5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Sigmoid:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        \n",
        "        self.Z = 1.0 / (1.0 + np.exp(-self.A))\n",
        "        \n",
        "        return self.Z\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "\n",
        "        return dZ * (1 - self.Z) * self.Z"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C64Dx1b0gku",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Tanh:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, A):\n",
        "        self.A = A\n",
        "        \n",
        "        return np.tanh(self.A)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        \n",
        "        return dZ * (1.0 - (np.tanh(self.A) ** 2))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rP2nTyh0VFh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ReLU:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "        \n",
        "    def forward(self, A):    \n",
        "        self.A = A\n",
        "        return np.maximum(self.A, 0)\n",
        "    \n",
        "    def backward(self, dZ):\n",
        "        return np.where(self.A > 0, dZ, 0)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3zavTDx0YrN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Softmax:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "    \n",
        "    def forward(self, A):\n",
        "        \n",
        "        return np.exp(A) / np.sum(np.exp(A), axis=1, keepdims=True)\n",
        "    \n",
        "    def backward(self, Z, y):\n",
        "        \n",
        "        dA = Z - y\n",
        "        \n",
        "        # 交差エントロピー誤差\n",
        "        batch_size = y.shape[0]\n",
        "        loss = -np.sum(y * np.log(Z)) / batch_size\n",
        "\n",
        "        return dA, loss"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ir6P5KLZ0cBH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "93257787-cd94-4338-9cfc-15ccd389c1e8"
      },
      "source": [
        "model = Scratch1dCNNClassifier(activation='tanh', n_nodes=[400, 200, 100], n_output=10, lr=0.001, optimizer='sgd', filter_num=3, filter_size=3)\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=10)\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch  1  processing . . .\n",
            "epoch  2  processing . . .\n",
            "epoch  3  processing . . .\n",
            "epoch  4  processing . . .\n",
            "epoch  5  processing . . .\n",
            "epoch  6  processing . . .\n",
            "epoch  7  processing . . .\n",
            "epoch  8  processing . . .\n",
            "epoch  9  processing . . .\n",
            "epoch  10  processing . . .\n",
            "epoch  11  processing . . .\n",
            "epoch  12  processing . . .\n",
            "epoch  13  processing . . .\n",
            "epoch  14  processing . . .\n",
            "epoch  15  processing . . .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_yoTNoi0d2G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "bbdce115-3dce-4162-c19d-8a8f55efcab7"
      },
      "source": [
        "print(\"accuracy : {}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"\\n\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy : 0.8883333333333333\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.94      0.94        53\n",
            "           1       0.97      1.00      0.99        73\n",
            "           2       0.83      0.91      0.87        64\n",
            "           3       0.92      0.77      0.84        62\n",
            "           4       0.91      0.91      0.91        67\n",
            "           5       0.81      0.91      0.86        56\n",
            "           6       0.90      0.90      0.90        52\n",
            "           7       0.80      0.93      0.86        57\n",
            "           8       0.93      0.77      0.84        52\n",
            "           9       0.88      0.81      0.85        64\n",
            "\n",
            "    accuracy                           0.89       600\n",
            "   macro avg       0.89      0.89      0.89       600\n",
            "weighted avg       0.89      0.89      0.89       600\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mULbsJN9S9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}