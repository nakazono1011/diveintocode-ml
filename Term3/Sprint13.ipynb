{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Sprint13.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1hhOGp38Kxt-18-F3bYL2UPSzfb67IPvE","authorship_tag":"ABX9TyPfqAWOHGuguraD/BWc+WlN"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"EADCvZwH3Osn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":444},"executionInfo":{"status":"ok","timestamp":1599713701383,"user_tz":-540,"elapsed":2479,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"9894df74-b229-43d0-a3e5-253b5cba64c3"},"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","import tensorflow as tf\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer"],"execution_count":1,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n","/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n","  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"Qq5ukRFlpRoM","colab_type":"text"},"source":["## 【問題1】スクラッチを振り返る\n","ここまでのスクラッチを振り返り、ディープラーニングを実装するためにはどのようなものが必要だったかを列挙してください。\n","\n","（例）\n","\n","* 重みを初期化する必要があった\n","* エポックのループが必要だった\n","\n","それらがフレームワークにおいてはどのように実装されるかを今回覚えていきましょう。"]},{"cell_type":"markdown","metadata":{"id":"y0ICZg8Npakt","colab_type":"text"},"source":["* Initializerクラスの実装が必要\n","* Optimizerの実装が必要\n","* 活性化関数の実装が必要\n","* ミニバッチサイズの分割が必要\n","* 損失関数の定義と実装が必要\n","* 畳み込み層、全結合層などの層のクラスのフォワード・バックの処理の実装が必要"]},{"cell_type":"markdown","metadata":{"id":"ntIddb8wqKCr","colab_type":"text"},"source":["## 【問題2】スクラッチとTensorFlowの対応を考える\n","以下のサンプルコードを見て、先ほど列挙した「ディープラーニングを実装するために必要なもの」がTensorFlowではどう実装されているかを確認してください。\n","\n","それを簡単に言葉でまとめてください。単純な一対一の対応であるとは限りません。\n"]},{"cell_type":"code","metadata":{"id":"tnnIdInQpWuh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":274},"executionInfo":{"status":"ok","timestamp":1599713702118,"user_tz":-540,"elapsed":3206,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"46111572-fa01-47a9-f5fd-37c118084e07"},"source":["\"\"\"\n","TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n","\"\"\"\n","# データセットの読み込み\n","dataset_path =\"/content/drive/My Drive/read_data/Iris/datasets_19_420_Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X)\n","# ラベルを数値に変換\n","y[y=='Iris-versicolor'] = 0\n","y[y=='Iris-virginica'] = 1\n","y = y.astype(np.int)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","class GetMiniBatch:\n","    \"\"\"\n","    ミニバッチを取得するイテレータ\n","\n","    Parameters\n","    ----------\n","    X : 次の形のndarray, shape (n_samples, n_features)\n","      訓練データ\n","    y : 次の形のndarray, shape (n_samples, 1)\n","      正解値\n","    batch_size : int\n","      バッチサイズ\n","    seed : int\n","      NumPyの乱数のシード\n","    \"\"\"\n","    def __init__(self, X, y, batch_size = 10, seed=0):\n","        self.batch_size = batch_size\n","        np.random.seed(seed)\n","        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n","        self.X = X[shuffle_index]\n","        self.y = y[shuffle_index]\n","        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n","    def __len__(self):\n","        return self._stop\n","    def __getitem__(self,item):\n","        p0 = item*self.batch_size\n","        p1 = item*self.batch_size + self.batch_size\n","        return self.X[p0:p1], self.y[p0:p1]        \n","    def __iter__(self):\n","        self._counter = 0\n","        return self\n","    def __next__(self):\n","        if self._counter >= self._stop:\n","            raise StopIteration()\n","        p0 = self._counter*self.batch_size\n","        p1 = self._counter*self.batch_size + self.batch_size\n","        self._counter += 1\n","        return self.X[p0:p1], self.y[p0:p1]\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 1\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(tf.random_normal([n_input, n_hidden1])),\n","        'w2': tf.Variable(tf.random_normal([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(tf.random_normal([n_hidden2, n_classes]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(tf.random_normal([n_hidden1])),\n","        'b2': tf.Variable(tf.random_normal([n_hidden2])),\n","        'b3': tf.Variable(tf.random_normal([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","# ネットワーク構造の読み込み                               \n","logits = example_net(X)\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=logits))\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# 推定結果\n","correct_pred = tf.equal(tf.sign(Y - 0.5), tf.sign(tf.sigmoid(logits) - 0.5))\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","# variableの初期化\n","init = tf.global_variables_initializer()\n","\n","# 計算グラフの実行\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","            total_acc += acc\n","        total_loss /= n_samples\n","        total_acc /= n_samples\n","        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","Epoch 0, loss : 0.0000, val_loss : 0.9864, acc : 1.000, val_acc : 0.875\n","Epoch 1, loss : 0.0000, val_loss : 1.6731, acc : 1.000, val_acc : 0.875\n","Epoch 2, loss : 0.0000, val_loss : 2.1405, acc : 1.000, val_acc : 0.875\n","Epoch 3, loss : 0.0000, val_loss : 1.3280, acc : 1.000, val_acc : 0.812\n","Epoch 4, loss : 0.0000, val_loss : 1.9336, acc : 1.000, val_acc : 0.875\n","Epoch 5, loss : 0.0000, val_loss : 0.0000, acc : 1.000, val_acc : 1.000\n","Epoch 6, loss : 0.0000, val_loss : 1.1370, acc : 1.000, val_acc : 0.875\n","Epoch 7, loss : 0.0000, val_loss : 0.0000, acc : 1.000, val_acc : 1.000\n","Epoch 8, loss : 0.0000, val_loss : 5.8109, acc : 1.000, val_acc : 0.750\n","Epoch 9, loss : 0.0000, val_loss : 0.0000, acc : 1.000, val_acc : 1.000\n","test_acc : 0.900\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Dwqks4Chsis6","colab_type":"text"},"source":["<tensorflowでの実装の流れ>\n","\n","1. ネットワーク構造と各層における演算を定義　⇒　logits\n","2. 目的関数を定義し、対象のネットワークを組み込む　⇒　loss_op\n","3. 最適化手法を定義し。最適化を行う関数を指定　⇒　train_op\n","\n","\n","* データの読み込み・前処理の流れは従来の手法と変わらない\n","* ミニバッチクラスの実装はtensorflowの学習の前に必要\n","* ハイパーパラメータの決定はtensorflowでも必要\n","  * 学習率\n","  * バッチサイズ\n","  * エポック数\n","  * 隠れ層の数とユニット数\n","\n","* ネットワーク構造の構築はtensorflowでも必要\n","  * 各層における演算処理の指定、活性化関数の指定、重みの初期値の指定を良きに計らうわけではない"]},{"cell_type":"markdown","metadata":{"id":"dGvsw5se228_","colab_type":"text"},"source":["## 【問題3】3種類全ての目的変数を使用したIrisのモデルを作成\n","Irisデータセットのtrain.csvの中で、目的変数Speciesに含まれる3種類全てを分類できるモデルを作成してください。\n","\n","Iris Species\n","\n","2クラスの分類と3クラス以上の分類の違いを考慮してください。それがTensorFlowでどのように書き換えられるかを公式ドキュメントなどを参考に調べてください。"]},{"cell_type":"code","metadata":{"id":"jqSUJQgepRHs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1599713759720,"user_tz":-540,"elapsed":1703,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"dacc28dd-dbae-4728-8484-64776af9d3dc"},"source":["#前処理工程====================================================================\n","# データセットの読み込み\n","dataset_path =\"/content/drive/My Drive/read_data/Iris/datasets_19_420_Iris.csv\"\n","df = pd.read_csv(dataset_path)\n","# データフレームから条件抽出\n","y = df[\"Species\"]\n","X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n","y = np.array(y)\n","X = np.array(X)\n","# ラベルを数値に変換\n","y[y=='Iris-setosa'] = 0\n","y[y=='Iris-versicolor'] = 1\n","y[y=='Iris-virginica'] = 2\n","y = y.astype(np.int)[:, np.newaxis]\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","\n","# 正規化とワンホット化\n","ss = StandardScaler().fit(X_train)\n","X_train = ss.transform(X_train)\n","X_test = ss.transform(X_test)\n","\n","ec = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n","y_train = ec.fit_transform(y_train)\n","y_test = ec.fit_transform(y_test)\n","\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","#==============================================================================\n","\n","# 各種パラメータの設定==========================================================\n","# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_classes = 3\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(\"float\", [None, n_input])\n","Y = tf.placeholder(\"float\", [None, n_classes])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)\n","#==============================================================================\n","\n","#ネットワーク構築==============================================================\n","def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    # 初期化クラスの定義\n","    initializer = tf.keras.initializers.he_normal()\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(initializer([n_input, n_hidden1])),\n","        'w2': tf.Variable(initializer([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(initializer([n_hidden2, n_classes]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(initializer([n_hidden1])),\n","        'b2': tf.Variable(initializer([n_hidden2])),\n","        'b3': tf.Variable(initializer([n_classes]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","\n","# ネットワーク構造の読み込み                               \n","logits = example_net(X)\n","# 目的関数\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# 推定結果\n","correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","# variableの初期化\n","init = tf.global_variables_initializer()\n","#==================================================================================\n","\n","# 計算グラフの実行==============================================================\n","with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","            total_acc += acc\n","        total_loss /= n_samples\n","        total_acc /= n_samples\n","        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 0.4138, val_loss : 0.7576, acc : 0.833, val_acc : 0.792\n","Epoch 1, loss : 0.0808, val_loss : 0.4370, acc : 1.000, val_acc : 0.792\n","Epoch 2, loss : 0.0707, val_loss : 0.3576, acc : 1.000, val_acc : 0.833\n","Epoch 3, loss : 0.0236, val_loss : 0.2661, acc : 1.000, val_acc : 0.875\n","Epoch 4, loss : 0.0228, val_loss : 0.2977, acc : 1.000, val_acc : 0.875\n","Epoch 5, loss : 0.0128, val_loss : 0.2343, acc : 1.000, val_acc : 0.917\n","Epoch 6, loss : 0.0101, val_loss : 0.2313, acc : 1.000, val_acc : 0.917\n","Epoch 7, loss : 0.0057, val_loss : 0.2169, acc : 1.000, val_acc : 0.917\n","Epoch 8, loss : 0.0039, val_loss : 0.2259, acc : 1.000, val_acc : 0.917\n","Epoch 9, loss : 0.0030, val_loss : 0.2597, acc : 1.000, val_acc : 0.917\n","test_acc : 1.000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FnEuf9kG22Oo","colab_type":"text"},"source":["## 【問題4】House Pricesのモデルを作成\n","回帰問題のデータセットであるHouse Pricesを使用したモデルを作成してください。\n","\n","この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使ってください。説明変数はさらに増やしても構いません。\n","\n","分類問題と回帰問題の違いを考慮してください。"]},{"cell_type":"markdown","metadata":{"id":"XOsiu6PhKt5d","colab_type":"text"},"source":["### データ読み込み・前処理"]},{"cell_type":"code","metadata":{"id":"6ybBm3YXKKQe","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599717245971,"user_tz":-540,"elapsed":1427,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["# データセットの読み込み\n","dataset_path =\"/content/drive/My Drive/read_data/HousePrice/train.csv\"\n","df = pd.read_csv(dataset_path)\n","\n","# データフレームから条件抽出\n","y = df[\"SalePrice\"]\n","X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n","y = np.array(y)\n","X = np.array(X)\n","y = y.astype(np.float)[:, np.newaxis]\n","\n","# trainとtestに分割\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n","# さらにtrainとvalに分割\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n","\n","# 正規化\n","x_scaler = StandardScaler()\n","x_scaler.fit(X_train)\n","X_train = x_scaler.transform(X_train)\n","X_val   = x_scaler.transform(X_val)\n","X_test  = x_scaler.transform(X_test)\n","\n","#対数変換\n","y_scaler = FunctionTransformer(func=np.log1p, inverse_func=np.expm1)\n","y_train = y_scaler.transform(y_train)\n","y_val   = y_scaler.transform(y_val)\n","y_test  = y_scaler.transform(y_test)"],"execution_count":72,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pe5VoGqeK4-p","colab_type":"text"},"source":["### ハイパーパラメータの設定"]},{"cell_type":"code","metadata":{"id":"zL_1AGPoLicF","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599717245972,"user_tz":-540,"elapsed":718,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["# ハイパーパラメータの設定\n","learning_rate = 0.01\n","batch_size = 10\n","num_epochs = 10\n","n_hidden1 = 50\n","n_hidden2 = 100\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_output = 1\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(tf.float32, [None, n_input])\n","Y = tf.placeholder(tf.float32, [None,1])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"],"execution_count":73,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RUWtFaNsPioF","colab_type":"text"},"source":["### ネットワーク＆計算グラフの構築"]},{"cell_type":"code","metadata":{"id":"H1F0xGHpPpBH","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599717314441,"user_tz":-540,"elapsed":738,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["def example_net(x):\n","    \"\"\"\n","    単純な3層ニューラルネットワーク\n","    \"\"\"\n","    initializer = tf.keras.initializers.he_normal()\n","\n","    # 重みとバイアスの宣言\n","    weights = {\n","        'w1': tf.Variable(initializer([n_input, n_hidden1])),\n","        'w2': tf.Variable(initializer([n_hidden1, n_hidden2])),\n","        'w3': tf.Variable(initializer([n_hidden2, n_output]))\n","    }\n","    biases = {\n","        'b1': tf.Variable(initializer([n_hidden1])),\n","        'b2': tf.Variable(initializer([n_hidden2])),\n","        'b3': tf.Variable(initializer([n_output]))\n","    }\n","    layer_1 = tf.add(tf.matmul(x, weights['w1']), biases['b1'])\n","    layer_1 = tf.nn.relu(layer_1)\n","    layer_2 = tf.add(tf.matmul(layer_1, weights['w2']), biases['b2'])\n","    layer_2 = tf.nn.relu(layer_2)\n","    layer_output = tf.matmul(layer_2, weights['w3']) + biases['b3'] # tf.addと+は等価である\n","    return layer_output\n","\n","# ネットワーク構造の読み込み                               \n","logits = example_net(X)\n","\n","# 目的関数(MSE)\n","loss_op = tf.losses.mean_squared_error(labels=Y, predictions=logits)\n","# 最適化手法\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","# 指標値計算\n","rmse = tf.log(tf.reduce_mean(tf.square(tf.math.expm1(Y)  - tf.math.expm1(logits))))\n","# variableの初期化\n","init = tf.global_variables_initializer()"],"execution_count":76,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kLd4Urc3Tfm0","colab_type":"text"},"source":["### 計算グラフの実行"]},{"cell_type":"code","metadata":{"id":"Hn3fQaXeTbKC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1599717317983,"user_tz":-540,"elapsed":3724,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"0e2a14f6-ac9e-4224-d3bf-1ddefa92ce34"},"source":["with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_score = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, score = sess.run([loss_op, rmse], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","            total_score += score\n","        total_loss /= n_samples\n","        total_score /= n_samples\n","        val_loss, val_score = sess.run([loss_op, rmse], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, score, val_score))\n","    test_score = sess.run(rmse, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_score : {:.3f}\".format(test_score))"],"execution_count":77,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 0.0966, val_loss : 0.3363, acc : 21.667, val_acc : 25.482\n","Epoch 1, loss : 0.0351, val_loss : 0.0940, acc : 20.806, val_acc : 22.141\n","Epoch 2, loss : 0.0435, val_loss : 0.0760, acc : 21.295, val_acc : 22.081\n","Epoch 3, loss : 0.0343, val_loss : 0.0666, acc : 21.158, val_acc : 21.788\n","Epoch 4, loss : 0.0294, val_loss : 0.0638, acc : 20.909, val_acc : 21.747\n","Epoch 5, loss : 0.0297, val_loss : 0.0631, acc : 20.815, val_acc : 21.638\n","Epoch 6, loss : 0.0302, val_loss : 0.0664, acc : 20.807, val_acc : 21.689\n","Epoch 7, loss : 0.0290, val_loss : 0.0728, acc : 20.820, val_acc : 21.741\n","Epoch 8, loss : 0.0315, val_loss : 0.0783, acc : 20.901, val_acc : 21.786\n","Epoch 9, loss : 0.0387, val_loss : 0.0907, acc : 21.139, val_acc : 21.941\n","test_score : 23.799\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0XUY3l2JlXnT","colab_type":"text"},"source":["## 【問題5】MNISTのモデルを作成\n","ニューラルネットワークのスクラッチで使用したMNISTを分類するモデルを作成してください。\n","\n","3クラス以上の分類という点ではひとつ前のIrisと同様です。入力が画像であるという点で異なります。\n","\n","スクラッチで実装したモデルの再現を目指してください。"]},{"cell_type":"markdown","metadata":{"id":"pruh--WjnCr5","colab_type":"text"},"source":["### データ読み込み・前処理"]},{"cell_type":"code","metadata":{"id":"05UExzuGXOjg","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599721067995,"user_tz":-540,"elapsed":869,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"],"execution_count":139,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmM4SQPAl-sI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1599721068407,"user_tz":-540,"elapsed":825,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"6e2caf0d-46f1-4afa-a074-21c1a40b92f8"},"source":["#サイズ指定\n","img_heigt = 28\n","img_width = 28\n","feature_size = int(img_heigt * img_width)\n","\n","#次元削減\n","X_train = X_train.reshape(-1, feature_size)\n","X_test  = X_test.reshape(-1, feature_size)\n","\n","#正規化のために型変換\n","X_train = X_train.astype(np.float32)\n","X_test  = X_test.astype(np.float32)\n","\n","#正規化\n","X_train /= 255\n","X_test /= 255\n","\n","#ワンホット変換\n","y_train = tf.keras.utils.to_categorical(y_train)\n","y_test = tf.keras.utils.to_categorical(y_test)\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=0)\n","\n","print(\"X shape:\", X_train.shape)\n","print(\"y shape:\", y_train.shape)"],"execution_count":140,"outputs":[{"output_type":"stream","text":["X shape: (54000, 784)\n","y shape: (54000, 10)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"h68nq3NUpMvf","colab_type":"text"},"source":["各種パラメータの設定"]},{"cell_type":"code","metadata":{"id":"gYFUALHlm8m-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599721341183,"user_tz":-540,"elapsed":653,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["learning_rate = 0.01 #学習率\n","batch_size = 2700 #バッチサイズ\n","num_epochs = 10  #エポック数\n","n_hidden1 = 256  #隠れ層１\n","n_hidden2 = 128  #隠れ層2\n","n_input = X_train.shape[1]\n","n_samples = X_train.shape[0]\n","n_output = y_train.shape[1]\n","# 計算グラフに渡す引数の形を決める\n","X = tf.placeholder(tf.float32, [None, n_input])\n","Y = tf.placeholder(tf.float32, [None, n_output])\n","# trainのミニバッチイテレータ\n","get_mini_batch_train = GetMiniBatch(X_train, y_train, batch_size=batch_size)"],"execution_count":147,"outputs":[]},{"cell_type":"code","metadata":{"id":"1UZCV2MCpHj_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1599721571188,"user_tz":-540,"elapsed":886,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}}},"source":["def network(x):\n","  initializer = tf.keras.initializers.he_normal()\n","  #重みとバイアスの宣言\n","  weights = {\n","      \"w1\": tf.Variable(initializer([n_input, n_hidden1])),\n","      \"w2\": tf.Variable(initializer([n_hidden1, n_hidden2])),\n","      \"w3\": tf.Variable(initializer([n_hidden2, n_output]))\n","  }\n","\n","  biases = {\n","      \"b1\": tf.Variable(initializer([n_hidden1,])),\n","      \"b2\": tf.Variable(initializer([n_hidden2,])),\n","      \"b3\": tf.Variable(initializer([n_output,]))\n","  }\n","\n","  #順伝播\n","  layer_1 = tf.matmul(x, weights[\"w1\"]) + biases[\"b1\"]\n","  layer_1 = tf.nn.relu(layer_1)\n","  layer_2 = tf.matmul(layer_1, weights[\"w2\"]) + biases[\"b2\"]\n","  layer_2 = tf.nn.relu(layer_2)\n","  layer_output = tf.matmul(layer_2, weights[\"w3\"]) + biases[\"b3\"]\n","  return layer_output\n","\n","logits = network(X)\n","\n","#損失関数\n","loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y, logits=logits))\n","\n","#最適化\n","optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n","train_op = optimizer.minimize(loss_op)\n","\n","# 推定結果\n","correct_pred = tf.equal(tf.argmax(Y, 1), tf.argmax(logits, 1))\n","\n","# 指標値計算\n","accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n","\n","# variableの初期化\n","init = tf.global_variables_initializer()"],"execution_count":152,"outputs":[]},{"cell_type":"code","metadata":{"id":"4oAsv9mGprIm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":203},"executionInfo":{"status":"ok","timestamp":1599721595200,"user_tz":-540,"elapsed":19313,"user":{"displayName":"K Zono","photoUrl":"","userId":"01969745139649658538"}},"outputId":"b2cdf97a-2670-4a93-9f20-5e2893de8bfc"},"source":["with tf.Session() as sess:\n","    sess.run(init)\n","    for epoch in range(num_epochs):\n","        # エポックごとにループ\n","        total_batch = np.ceil(X_train.shape[0]/batch_size).astype(np.int)\n","        total_loss = 0\n","        total_acc = 0\n","        for i, (mini_batch_x, mini_batch_y) in enumerate(get_mini_batch_train):\n","            # ミニバッチごとにループ\n","            sess.run(train_op, feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: mini_batch_x, Y: mini_batch_y})\n","            total_loss += loss\n","            total_acc += acc\n","        total_loss /= n_samples\n","        total_acc /= n_samples\n","        val_loss, val_acc = sess.run([loss_op, accuracy], feed_dict={X: X_val, Y: y_val})\n","        print(\"Epoch {}, loss : {:.4f}, val_loss : {:.4f}, acc : {:.3f}, val_acc : {:.3f}\".format(epoch, loss, val_loss, acc, val_acc))\n","    test_acc = sess.run(accuracy, feed_dict={X: X_test, Y: y_test})\n","    print(\"test_acc : {:.3f}\".format(test_acc))"],"execution_count":153,"outputs":[{"output_type":"stream","text":["Epoch 0, loss : 0.2997, val_loss : 0.2585, acc : 0.911, val_acc : 0.923\n","Epoch 1, loss : 0.1890, val_loss : 0.1573, acc : 0.939, val_acc : 0.951\n","Epoch 2, loss : 0.1344, val_loss : 0.1233, acc : 0.956, val_acc : 0.961\n","Epoch 3, loss : 0.0990, val_loss : 0.1023, acc : 0.966, val_acc : 0.969\n","Epoch 4, loss : 0.0753, val_loss : 0.0923, acc : 0.977, val_acc : 0.973\n","Epoch 5, loss : 0.0561, val_loss : 0.0846, acc : 0.984, val_acc : 0.973\n","Epoch 6, loss : 0.0461, val_loss : 0.0861, acc : 0.986, val_acc : 0.973\n","Epoch 7, loss : 0.0346, val_loss : 0.0811, acc : 0.991, val_acc : 0.975\n","Epoch 8, loss : 0.0380, val_loss : 0.0965, acc : 0.989, val_acc : 0.970\n","Epoch 9, loss : 0.0268, val_loss : 0.0822, acc : 0.992, val_acc : 0.974\n","test_acc : 0.975\n"],"name":"stdout"}]}]}